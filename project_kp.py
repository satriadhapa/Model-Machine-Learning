# -*- coding: utf-8 -*-
"""Project KP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DKlHzUZi2CpebaiGlalDtL1sGCgdapcy

## IMPORT LIBRARY
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas.core.algorithms as algos
from pandas import Series
# import plotly as py
# import plotly.graph_objs as go
# import plotly.express as px
# from plotly.subplots import make_subplots
# from plotly.offline import init_notebook_mode
# init_notebook_mode(connected = True)

import scipy.stats.stats as stats
import re
import traceback
import string
from imblearn.over_sampling import SMOTENC
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, confusion_matrix,roc_curve, auc, \
roc_auc_score, precision_score, recall_score, precision_recall_curve
from sklearn.model_selection import cross_validate, cross_val_score, train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.preprocessing import LabelEncoder

"""## Getting Data"""

data = pd.read_csv('dataset/df.csv')
data.head()

data['quantity'] = round(data['quantity'])

"""## BUSSINESS UNDERSTANDING FROM DATA"""

data.head()

data['gender'].value_counts()

data.shape

data.describe()

"""## DATA PREPROCESSING"""

data.isna().sum()

"""terdapat nilai NAN pada feature promo_code sebanyak 11853 yang harus kita proses, kita dapat melakukan drop atau fillna tergantung kebutuhan."""

data.fillna("tidak Pakai Promo", inplace=True)

data.isna().sum()

data.duplicated().sum()

data['traffic_source'].unique()

data['traffic_source'] = data['traffic_source'].replace("['MOBILE' 'WEB']", "Nan")
data['traffic_source'] = data['traffic_source'].replace("Nan", "")
data['traffic_source'] = data['traffic_source'].replace("", )

data['traffic_source'].unique()

"""## DATA MINING AND MODELLING"""

X = data.drop(['customer_id', 'churned'], axis=1)
y = data['churned']

y.value_counts(normalize= True)

"""berdasarkan hasil normalisasi pada target variabel, didapatkan bahwa ada ketidakseimbangan yang terjadi pada data target y yaitu churn 80% dan not churn 20%. kita harus membuat data diatas tersebut menjadi seimbang dengan teknik oversampling menggunakan SMOTENC(SMOTE NOMINAL DAN CONTINOUS)"""

# SMOTENC oversampling
sm = SMOTENC(random_state=0, sampling_strategy={0:40000}, 
             categorical_features=[0, 1, 2, 11, 12, 13, 14])
X_res, y_res = sm.fit_resample(X, y)

y_res.value_counts(normalize=True)

"""# preprocess data with other methods"""

data.columns

"""Feature Selection"""

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

X_res['gender'] = le.fit_transform(X_res['gender'])
X_res['device_type'] = le.fit_transform(X_res['device_type'])
X_res['home_location'] = le.fit_transform(X_res['home_location'])
X_res['payment_method'] = le.fit_transform(X_res['payment_method'])
X_res['traffic_source'] = le.fit_transform(X_res['traffic_source'])
X_res['promo_code'] = le.fit_transform(X_res['promo_code'])
X_res['event_name'] = le.fit_transform(X_res['event_name'])

# data_norm = (data - data.min()) / (data.max() - data.min())

X_res

"""## SPLIT TRAIN TEST DATA"""

X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=2023, shuffle= True, stratify= None)

"""# ALGORITMA RANDOM FOREST CLASSIFIER"""

rfc = RandomForestClassifier(n_estimators=100,
                             criterion='entropy',
                             verbose = 20,
                             warm_start= False, 
                             random_state=2023,
                             max_samples= 0.2)
rfc.fit(X_train, y_train)

y_pred = rfc.predict(X_test) # Predicting the Test set results

from sklearn.metrics import mean_absolute_error
print('Confusion Matrix:\n', confusion_matrix(y_test, y_pred))
print('Classification Report:\n', classification_report(y_test, y_pred))
print('accuracy train :', accuracy_score(y_true=y_train, y_pred= rfc.predict(X_train)))
print('Accuracy:', accuracy_score(y_test, y_pred))
print('AUC & ROC: ', roc_auc_score(y_test, y_pred))
print('Precision : ', precision_score(y_test, y_pred))
print("Mean Absolute Error:", mean_absolute_error(y_test, y_pred))

sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')

from sklearn.metrics import roc_curve, auc

y_score = rfc.predict_proba(X_test)[:, 1]

fpr, tpr, threshold = roc_curve(y_test, y_score)

roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, lw=1, alpha=0.8, label='ROC %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], linestyle='--', lw=1, color='gray', alpha=0.8)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

"""# ALGORITMA LINEAR SUPPORT VECTOR MACHINE CLASSIFIER(SVC)"""

from sklearn.svm import LinearSVC
svm = LinearSVC(random_state=0)

svm.fit(X_train,y_train)

y_pred = svm.predict(X_test)

from sklearn.metrics import mean_absolute_error
print('Confusion Matrix:\n', confusion_matrix(y_test, y_pred))
print('Classification Report:\n', classification_report(y_test, y_pred))
print('accuracy train :', accuracy_score(y_true=y_train, y_pred=svm.predict(X_train)))
print('Accuracy:', accuracy_score(y_test, y_pred))
print('Precision : ', precision_score(y_test, y_pred))
print('AUC & ROC: ', roc_auc_score(y_test, y_pred))
print("Mean Absolute Error:", mean_absolute_error(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')

from sklearn.metrics import RocCurveDisplay

svm_disp = RocCurveDisplay.from_estimator(svm, X_test, y_test)
plt.show()

X_test.head(16)

"""## CROSS VALIDATION AND HYPERPARAMETER TUNING"""

# cross validation function
def get_score(n_estimators):
  rfc = RandomForestClassifier(n_estimators, random_state=0, max_depth=20)
  scores = cross_validate(rfc, X_train, y_train,
                          scoring=('roc_auc', 'recall', 'f1'))
  return scores['test_roc_auc'].mean(), scores['test_recall'].mean(), \
  scores['test_f1'].mean()

# hyperparameter tuning
results = {}
for i in range(1, 6):
    results[100*i] = get_score(100*i)

cv_results4 = pd.DataFrame(results).transpose()
cv_results4 = cv_results4.rename(columns={0: 'AUC Score', 1: 'Recall Score', 
                                          2: 'F1 Score'})
cv_results4.sort_values(by=['Recall Score'], ascending=False)

X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, 
                                                    test_size=0.2, 
                                                    random_state=0)

rfc = RandomForestClassifier(max_depth=20, n_estimators=300, random_state=0)

rfc.fit(X_train, y_train)

y_train4 = rfc.predict(X_train)

y_pred4 = rfc.predict(X_test)

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_pred4)

plt.figure(figsize=(9, 5))

cf_matrix = confusion_matrix(y_test, y_pred4)
group_names = ['True Negative', 'False Positive', 'False Negative',
               'True Positive']
group_counts = ['{0:0.0f}'.format(value) for value in
                cf_matrix.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f'{v1}\n{v2}\n{v3}' for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)

sns.set(font_scale=1.5)
sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues').set(
    xlabel='Predicted data', ylabel='Actual data')

# training set
from sklearn.metrics import classification_report
print(classification_report(y_train, y_train4))
print(f'AUC score: {roc_auc_score(y_train, y_train4)}')
print(f'Recall score: {recall_score(y_train, y_train4)}')

# test set
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred4))
print('Accuracy:', accuracy_score(y_test, y_pred4))
print('Precision : ', precision_score(y_test, y_pred4))
print('AUC & ROC: ', roc_auc_score(y_test, y_pred4))
print(f'Recall score: {recall_score(y_test, y_pred4)}')
print("Mean Absolute Error:", mean_absolute_error(y_test, y_pred4))

# cross validation function
def get_score2(C, max_iter):
  lsvc = LinearSVC(random_state=0, C=C, max_iter=max_iter,dual = False)
  scores = cross_validate(svm, X_train, y_train,
                          scoring=('roc_auc', 'recall', 'f1'))
  return scores['test_roc_auc'].mean(), scores['test_recall'].mean(), \
  scores['test_f1'].mean()

# hyperparameter tuning
C = [1.0, 2.0, 3.0, 4.0, 5.0]
results2 = {}
for i in C:
    results2[i, 1000*i] = get_score2(i, 1000*i)

cv_results2 = pd.DataFrame(results2).transpose()
cv_results2 = cv_results2.reset_index()
cv_results2 = cv_results2.rename(columns={'level_0': 'C', 'level_1': 'max_iter',
                                          0: 'AUC Score', 1: 'Recall Score', 
                                          2: 'F1 Score'})
cv_results2 = cv_results2.sort_values(by=['Recall Score'], ascending=False)
cv_results2

lsvc = LinearSVC(random_state=0, C=1.0, max_iter=4000)

lsvc.fit(X_train, y_train)

y_pred2 = lsvc.predict(X_test)

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_pred2)

plt.figure(figsize=(9, 5))

cf_matrix = confusion_matrix(y_test, y_pred2)
group_names = ['True Negative', 'False Positive', 'False Negative',
               'True Positive']
group_counts = ['{0:0.0f}'.format(value) for value in
                cf_matrix.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f'{v1}\n{v2}\n{v3}' for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)

sns.set(font_scale=1.5)
sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues').set(
    xlabel='Predicted data', ylabel='Actual data')

# test set
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred2))
print('Accuracy:', accuracy_score(y_test, y_pred2))
print('Precision : ', precision_score(y_test, y_pred2))
print('AUC & ROC: ', roc_auc_score(y_test, y_pred2))
print(f'Recall score: {recall_score(y_test, y_pred2)}')
print("Mean Absolute Error:", mean_absolute_error(y_test, y_pred2))

print("Linear SVC:")
print('Accuracy:', accuracy_score(y_test, y_pred2))
print('Precision : ', precision_score(y_test, y_pred2))
print('AUC & ROC: ', roc_auc_score(y_test, y_pred2))
print(f'Recall score: {recall_score(y_test, y_pred2)}')
print("Mean Absolute Error:", mean_absolute_error(y_test, y_pred2))
print("\nRandom Forest Classifier:")
print('Accuracy:', accuracy_score(y_test, y_pred4))
print('Precision : ', precision_score(y_test, y_pred4))
print('AUC & ROC: ', roc_auc_score(y_test, y_pred4))
print(f'Recall score: {recall_score(y_test, y_pred4)}')
print("Mean Absolute Error:", mean_absolute_error(y_test, y_pred4))

"""# TESTING WITH NEW DATA"""

new_data = np.array([[0,0,6,18,3,3821.356845,9849262198,6.045599,1.0,190614,1232,0,1,1,0]]) 
prediction = rfc.predict(new_data)
if prediction == 0:
    print("customer will not churn")
elif prediction == 1:
    print("customer will churn")

